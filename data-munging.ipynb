{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook handles downloading, loading, parsing, joining, and saving the combined PLUTO and Rolling Sales Data datasets.\n",
    "\n",
    "Sources:\n",
    "* [Rolling Sales Data](https://www1.nyc.gov/site/finance/taxes/property-rolling-sales-data.page)\n",
    "* [PLUTO Data](http://www1.nyc.gov/site/planning/data-maps/open-data/dwn-pluto-mappluto.page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rolling sales data is provided as lightly formatted `xls` files (Excel):\n",
    "\n",
    "![alt text](./rolling-sales-data-excel-screencap.png \"Logo Title Text 1\")\n",
    "\n",
    "Luckily the extraneous details are easily patched up post-import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:22<00:00,  4.44s/it]\n"
     ]
    }
   ],
   "source": [
    "rolling_sales_data = dict()\n",
    "rolling_sales_data_key_pairs = {'Manhattan': 'manhattan',\n",
    "                                'Brooklyn': 'brooklyn',\n",
    "                                'Queens': 'queens',\n",
    "                                'Bronx': 'bronx',\n",
    "                                'Staten Island': 'statenisland'}\n",
    "for b_k, b_xls in tqdm(list(rolling_sales_data_key_pairs.items())):\n",
    "    borough_rsd = pd.read_excel('https://www1.nyc.gov/assets/finance/downloads/pdf/rolling_sales/rollingsales_{0}.xls'.format(b_xls))\n",
    "    borough_rsd.columns = borough_rsd.iloc[3].values\n",
    "    borough_rsd = borough_rsd[4:]\n",
    "    rolling_sales_data[b_k] = borough_rsd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLUTO data is provided as borough-denominated `csv` files packaged into a `zip`. The following code bit unpacks the data and rekeys the file (`QN.csv`, `BK.csv`, `BX.csv`, `SI.csv`, `Mn.csv`) to match the lexicon used for the rolling sales data, above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/Users/Honors/anaconda/envs/residential-housing/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (4,6,7,8,10,11,50,52,53,77,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 20%|██        | 1/5 [00:03<00:12,  3.05s/it]/Users/Honors/anaconda/envs/residential-housing/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (6,7,8,10,27,50,52,53,77,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      " 60%|██████    | 3/5 [00:12<00:07,  3.68s/it]/Users/Honors/anaconda/envs/residential-housing/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2723: DtypeWarning: Columns (6,7,10,11,50,52,53,77,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "100%|██████████| 5/5 [00:21<00:00,  3.87s/it]\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('http://www1.nyc.gov/assets/planning/download/zip/data-maps/open-data/nyc_pluto_15v1.zip')\n",
    "pluto_key_pairs = {'Manhattan': 'Mn.csv',\n",
    "                   'Brooklyn': 'BK.csv',\n",
    "                   'Bronx': 'BX.csv',\n",
    "                   'Staten Island': 'SI.csv',\n",
    "                   'Queens': 'QN.csv'}\n",
    "pluto_data = dict()\n",
    "for b_k, b_csv in tqdm(list(pluto_key_pairs.items())):\n",
    "    with zipfile.ZipFile(io.BytesIO(r.content)) as ar:\n",
    "        borough_pluto = pd.read_csv(ar.open(b_csv))\n",
    "        pluto_data[b_k] = borough_pluto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is provided on a per-borough basis, and since we would like to study the entire city, we must now flatten each set of tables into two big tables. Along the way we encode an additional `Borough` column, to preserve information.\n",
    "\n",
    "**Note**: the `Borough` mapping is a new column in the rolling sales dataset; a prexisting (numerically encoded) `BOROUGH` column is removed. The mapping overlays and replaces an older (acronym-encoded) column in the `PLUTO` one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:11<00:00,  2.49s/it]\n"
     ]
    }
   ],
   "source": [
    "rolling_sales_agglom = pd.DataFrame(columns=rolling_sales_data['Manhattan'].columns)\n",
    "pluto_data_agglom = pd.DataFrame(columns=pluto_data['Manhattan'].columns)\n",
    "for b_k in tqdm(pluto_key_pairs.keys()):\n",
    "    pluto_data[b_k]['Borough'] = rolling_sales_data[b_k]['Borough'] = b_k\n",
    "    rolling_sales_agglom = pd.concat([rolling_sales_agglom, rolling_sales_data[b_k]], ignore_index=True)\n",
    "    pluto_data_agglom = pd.concat([pluto_data_agglom, pluto_data[b_k]], ignore_index=True)\n",
    "del rolling_sales_agglom['BOROUGH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we flatten these two files into one by performing an outer join on the `(Borough, Block, Lot)` unique key (this is [standard](http://www1.nyc.gov/nyc-resources/service/1232/borough-block-lot-bbl-lookup)).\n",
    "\n",
    "In order to do this we must first remap the column names in the rolling sales dataset from `SPACED ALL CAPS` to `NoSpaceCamelCase` (as ued by `PLUTO`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling_sales_agglom.columns = [c.title().replace(' ', '') for c in list(rolling_sales_agglom.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we hit a roadblock.\n",
    "\n",
    "Our assumption going into this project was that the `Borough`-`Block`-`Lot` columns present in both PLUTO and the Rolling Sales dataset (these are an identifier used for taxation purposes) are equivalent, allowing us to use this combo as a unique key for a join. However, this assumption turns out to be incorrect.\n",
    "\n",
    "The Rolling Sales dataset contains information on the sale of both individual apartments and of whole buildings, but does not contain the square footage of the apartment sales in the data.\n",
    "\n",
    "The PLUTO dataset contains information on the square footage of entire buildings, but not on that of individual apartments. This is because instead of using the usual Tax-Block-Lot system PLUTO defines and uses its own Lot configuration, painting over condominiums with multiple lots in a single building by merging them into one Lot. This is useful for geospatial visualization but voids the use of the dataset for ordinary apartment-based residential lookup: the Rolling Sales dataset contains sales information on individual apartments which, as a consequence of this tweak, cannot be mapped to any of the records in PLUTO.\n",
    "\n",
    "We'll have to remove apartments from the dataset and do without them. Weirdly the sentinel value in this case is `'            '`, as in, a long space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'            '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_sales_agglom.ix[0, :]['ApartmentNumber']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs_a_f = rolling_sales_agglom[rolling_sales_agglom['ApartmentNumber'] == '            ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not every record in the Rolling Sales dataset represents an actual sale. A large number of records are of what are effectively deed transfers: sales of a building for either `$0` or occassionally some paltry some, usually between family members, sometimes as a part of a contract, and so on. Since these records do not encode any actual information they should be dropped.\n",
    "\n",
    "`$1000` is arbitrarily chosen as a cutoff value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rs_a_f = rs_a_f[rs_a_f['SalePrice'] > 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the primary key values there are a handful of columns which are present in both datasets. However, these are encoded somewhat differently. For example, `Address` is present in both `PLUTO` and the rolling sales data, but is not consistently formatted in the former&mdash;many entries have what appears to be a leading space that would need to be stripped first.\n",
    "\n",
    "Considering that the alphanumerical `Borough-Block-Lot` combination is standardly encoded and fully unique (*for our chosen subcase*), we can simply not consider these additional columns, as adding them to the join won't do anything for us (and create more problems than it solves).\n",
    "\n",
    "The rolling sales data contains a number of variables which are more or less copies of the data contained in `PLUTO`. Since we cannot construct a generalized classifier based on variables which are not everywhere present (technically you can `GLM`-encode `NaN` values, but this is a poor idea), we will extract only one column of interest from the rolling sales data, the `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rolling_non_dups = ['Borough', 'Block', 'Lot', 'SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rolling_pluto = pd.merge(rs_a_f[rolling_non_dups], pluto_data_agglom,\n",
    "                         how='outer', on=['Borough', 'Block', 'Lot'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's not immediately apparent why, but this resulted in more records than expected. I chose to defer investigating this until a second stage of the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14472"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rolling_pluto) - len(pluto_data_agglom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However `SalePrice`-populated mergers fired correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rs_a_f) - len(rolling_pluto[rolling_pluto['SalePrice'] >= 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable for this analysis is `BldgArea`, so a couple more adjustments: let's drop entries missing this value or having a `BldgArea` of `0` and drop entries missing an `Address` (parks and the like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rolling_pluto = rolling_pluto[rolling_pluto['BldgArea'] > 0]\n",
    "rolling_pluto = rolling_pluto[rolling_pluto['Address'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we are ready to split the dataset into two partitions. The *predictor partition* contains all of our records with associated sales data&mdash;the ground truths on which we will build our model. The *predicted partition* contains all of the fresh records (the vast majority) which do not have sales data associated with them.\n",
    "\n",
    "Once we are satisfied with the power of our model (constructed using the predictor data) we will apply it to the rest of the city (predicted data) and visualize the results for explanatory analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r_p_pre = rolling_pluto[rolling_pluto['SalePrice'].notnull()]\n",
    "r_p_post = rolling_pluto[rolling_pluto['SalePrice'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's enrich the dataset with a calculated variable for value by square footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Honors/anaconda/envs/residential-housing/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "/Users/Honors/anaconda/envs/residential-housing/lib/python3.5/site-packages/ipykernel/__main__.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Ignore the warning.\n",
    "sqft_values = r_p_pre['SalePrice'] / r_p_pre['BldgArea']\n",
    "r_p_pre['ValueSqFt'] = sqft_values\n",
    "r_p_post['ValueSqFt'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index appears to be some combination out of wack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_p_pre.reset_index(drop=True, inplace=True)\n",
    "r_p_post.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That does it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r_p_pre.to_csv('nyc_building_sales.csv')\n",
    "r_p_post.to_csv('nyc_buildings.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
